<!doctype html>
<html lang="en">
  
  <head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="stylesheet" href="static/css/main.css">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <script src="static/js/typeahead.bundle.js"></script>
  <link rel="stylesheet" href="static/css/typeahead.css">
  <link rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
    crossorigin="anonymous">
  <link rel="stylesheet" href="static/css/lazy_load.css">
  <script src="static/js/lazy_load.js"></script>
  <title> ICLR: Robust Reinforcement Learning for Continuous Control with Model Misspecification </title>
</head>
  <meta name="citation_title" content="Robust Reinforcement Learning for Continuous Control with Model Misspecification" />
  
  <meta name="citation_author" content="Daniel J. Mankowitz" />
  
  <meta name="citation_author" content="Nir Levine" />
  
  <meta name="citation_author" content="Rae Jeong" />
  
  <meta name="citation_author" content="Abbas Abdolmaleki" />
  
  <meta name="citation_author" content="Jost Tobias Springenberg" />
  
  <meta name="citation_author" content="Yuanyuan Shi" />
  
  <meta name="citation_author" content="Jackie Kay" />
  
  <meta name="citation_author" content="Todd Hester" />
  
  <meta name="citation_author" content="Timothy Mann" />
  
  <meta name="citation_author" content="Martin Riedmiller" />
  
  <meta name="citation_publication_date" content="2020/04"/>
  <meta name="citation_conference_title" content="Eighth International Conference on Learning Representations" />
  <meta name="citation_abstract" content="We provide a framework for incorporating robustness -- to perturbations in the transition dynamics which we refer to as model misspecification -- into continuous control Reinforcement Learning (RL) algorithms. We specifically focus on incorporating robustness into a state-of-the-art continuous control RL algorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve this by learning a policy that optimizes for a worst case, entropy-regularized, expected return objective and derive a corresponding robust entropy-regularized Bellman contraction operator. In addition, we introduce a less conservative, soft-robust, entropy-regularized objective with a corresponding Bellman operator. We show that both, robust and soft-robust policies, outperform their non-robust counterparts in nine Mujoco domains with environment perturbations. In addition, we show improved robust performance on a challenging, simulated, dexterous robotic hand. Finally, we present multiple investigative experiments that provide a deeper insight into the robustness framework; including an adaptation to another continuous control RL algorithm. Performance videos can be found online at https://sites.google.com/view/robust-rl." />
  <meta name="citation_pdf_url" content="http://www.openreview.net/pdf?id=HJgC60EtwB" />
  
  <meta name="citation_keywords" content="continuous control" />
  
  <meta name="citation_keywords" content="optimization" />
  
  <meta name="citation_keywords" content="perturbation" />
  
  <meta name="citation_keywords" content="reinforcement learning" />
  
  <meta name="citation_keywords" content="robustness" />
  
  <body >
    <!-- NAV -->
    
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment.min.js"
  integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment-timezone/0.5.28/moment-timezone-with-data.min.js"
  integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
  crossorigin="anonymous"></script>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
    <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          
          <a class="nav-link" href="index.html">Home</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="calendar.html">Schedule</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="workshops.html">Workshops</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="papers.html">Papers</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="about.html">Help</a>
          
        </li>
        
      </ul>
    </div>
  </div>
</nav>
    <div class="container">
      <!-- Title -->
      <div class="pp-card m-3" style="">
        <div class="card-header">
          <h2 class="card-title main-title text-center" style="">
            Robust Reinforcement Learning for Continuous Control with Model Misspecification
          </h2>
          <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Daniel J. Mankowitz" class="text-muted">Daniel J. Mankowitz</a>,
            
            <a href="papers.html?filter=authors&search=Nir Levine" class="text-muted">Nir Levine</a>,
            
            <a href="papers.html?filter=authors&search=Rae Jeong" class="text-muted">Rae Jeong</a>,
            
            <a href="papers.html?filter=authors&search=Abbas Abdolmaleki" class="text-muted">Abbas Abdolmaleki</a>,
            
            <a href="papers.html?filter=authors&search=Jost Tobias Springenberg" class="text-muted">Jost Tobias Springenberg</a>,
            
            <a href="papers.html?filter=authors&search=Yuanyuan Shi" class="text-muted">Yuanyuan Shi</a>,
            
            <a href="papers.html?filter=authors&search=Jackie Kay" class="text-muted">Jackie Kay</a>,
            
            <a href="papers.html?filter=authors&search=Todd Hester" class="text-muted">Todd Hester</a>,
            
            <a href="papers.html?filter=authors&search=Timothy Mann" class="text-muted">Timothy Mann</a>,
            
            <a href="papers.html?filter=authors&search=Martin Riedmiller" class="text-muted">Martin Riedmiller</a>
            
          </h3>
          <p class="card-text text-center"><span class="">Keywords:</span>
            
            <a href="papers.html?filter=keywords&search=continuous control" class="text-secondary text-decoration-none">continuous control</a>,
            
            <a href="papers.html?filter=keywords&search=optimization" class="text-secondary text-decoration-none">optimization</a>,
            
            <a href="papers.html?filter=keywords&search=perturbation" class="text-secondary text-decoration-none">perturbation</a>,
            
            <a href="papers.html?filter=keywords&search=reinforcement learning" class="text-secondary text-decoration-none">reinforcement learning</a>,
            
            <a href="papers.html?filter=keywords&search=robustness" class="text-secondary text-decoration-none">robustness</a>
            
          </p>
          <div class="text-center p-3">
            <a class="card-link" data-toggle="collapse" role="button" href="#details">
            Abstract
            </a>
            <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf?id=HJgC60EtwB">
            Paper
            </a>
            
            <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=HJgC60EtwB">
            Reviews
            </a>
            <!--  -->
            <!-- <a href="38925864" target="_blank"  class="card-link"> -->
            <!--   Slides -->
            <!-- </a> -->
            <!--  -->
            <!-- </div> -->
            <!-- <div class="text-center "> -->
            <!-- <a href="chat.html?room=channel/poster_222" target="_blank"  class="card-link"> -->
            <!-- Chat -->
            <!-- </a> -->
          </div>
          <div class=" text-center text-muted text-monospace ">
            
          </div>
        </div>
      </div>
      <div id="details" class="pp-card m-3 collapse">
        <div class="card-body">
          <p class="card-text">
          <div id="abstractExample">
            <span class="font-weight-bold">Abstract:</span>
            We provide a framework for incorporating robustness -- to perturbations in the transition dynamics which we refer to as model misspecification -- into continuous control Reinforcement Learning (RL) algorithms. We specifically focus on incorporating robustness into a state-of-the-art continuous control RL algorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve this by learning a policy that optimizes for a worst case, entropy-regularized, expected return objective and derive a corresponding robust entropy-regularized Bellman contraction operator. In addition, we introduce a less conservative, soft-robust, entropy-regularized objective with a corresponding Bellman operator. We show that both, robust and soft-robust policies, outperform their non-robust counterparts in nine Mujoco domains with environment perturbations. In addition, we show improved robust performance on a challenging, simulated, dexterous robotic hand. Finally, we present multiple investigative experiments that provide a deeper insight into the robustness framework; including an adaptation to another continuous control RL algorithm. Performance videos can be found online at https://sites.google.com/view/robust-rl.
          </div>
          </p>
          <p></p>
        </div>
      </div>
    </div>
    <!-- SlidesLive -->
    <div class="container" style="background-color:white; padding: 0px;">
      <div class="row m-2">
        <div class="col-md-12 col-xs-12 my-auto p-2" >

          <div id="presentation-embed-38925864" class="slp my-auto"></div>
          <script src='https://slideslive.com/embed_presentation.js'></script>
          <script>
            embed = new SlidesLiveEmbed('presentation-embed-38925864', {
            presentationId: '38925864',
            autoPlay: false, // change to true to autoplay the embedded presentation
            verticalEnabled: true,
            allowHiddenControlsWhenPaused: true,
            hideTitle: true
            });
          </script>
        </div>
      </div>
    </div>

    <!-- Recs -->
    <p></p>
    <div  class="container" style="padding-bottom: 30px; padding-top:30px">
      <center>
        <h2> Similar Papers </h2>
      </center>
    </div>
    <p></p>
    <div  class="container" >
      <div class="row">
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_rke7geHtwH.html" class="text-muted">
                <h5 class="card-title" align="center">Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Noah Siegel,
                
                Jost Tobias Springenberg,
                
                Felix Berkenkamp,
                
                Abbas Abdolmaleki,
                
                Michael Neunert,
                
                Thomas Lampe,
                
                Roland Hafner,
                
                Nicolas Heess,
                
                Martin Riedmiller,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rke7geHtwH.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_S1xKd24twB.html" class="text-muted">
                <h5 class="card-title" align="center">SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Siddharth Reddy,
                
                Anca D. Dragan,
                
                Sergey Levine,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/S1xKd24twB.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_SylOlp4FvH.html" class="text-muted">
                <h5 class="card-title" align="center">V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                H. Francis Song,
                
                Abbas Abdolmaleki,
                
                Jost Tobias Springenberg,
                
                Aidan Clark,
                
                Hubert Soyer,
                
                Jack W. Rae,
                
                Seb Noury,
                
                Arun Ahuja,
                
                Siqi Liu,
                
                Dhruva Tirumala,
                
                Nicolas Heess,
                
                Dan Belov,
                
                Martin Riedmiller,
                
                Matthew M. Botvinick,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SylOlp4FvH.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
      </div>
    </div>
    <script type="text/javascript">
  $(document).ready(function () {
  
  if (location.hash !== '') {
  $('a[href="' + location.hash + '"]').tab('show');
  }
  
  $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
  var hash = $(e.target).attr("href");
  if (hash.substr(0,1) == "#") {
  var position = $(window).scrollTop();
  location.replace("#" + hash.substr(1));
  $(window).scrollTop(position);
  }
  });
  
  });
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163955028-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  
  gtag('config', 'UA-163955028-1');
</script>
<footer class="footer bg-light p-4">
  <div class="container">
    <p class="float-right"><a href="#">Back to Top</a></p>
    <p class="text-center">© 2020 International Conference on Learning Representations</p>
  </div>
</footer>
  </body>
  <script src="static/js/time-extend.js"></script>
<script>
  $(document).ready(()=>{
    add_local_tz('.session_times');
  })
</script>
</html>