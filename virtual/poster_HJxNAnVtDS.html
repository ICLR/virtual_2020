<!doctype html>
<html lang="en">
  
  <head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="stylesheet" href="static/css/main.css">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <script src="static/js/typeahead.bundle.js"></script>
  <link rel="stylesheet" href="static/css/typeahead.css">
  <link rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
    crossorigin="anonymous">
  <link rel="stylesheet" href="static/css/lazy_load.css">
  <script src="static/js/lazy_load.js"></script>
  <title> ICLR: On the Convergence of FedAvg on Non-IID Data </title>
</head>
  <meta name="citation_title" content="On the Convergence of FedAvg on Non-IID Data" />
  
  <meta name="citation_author" content="Xiang Li" />
  
  <meta name="citation_author" content="Kaixuan Huang" />
  
  <meta name="citation_author" content="Wenhao Yang" />
  
  <meta name="citation_author" content="Shusen Wang" />
  
  <meta name="citation_author" content="Zhihua Zhang" />
  
  <meta name="citation_publication_date" content="2020/04"/>
  <meta name="citation_conference_title" content="Eighth International Conference on Learning Representations" />
  <meta name="citation_abstract" content="Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \texttt{FedAvg} on non-iid data and establish a convergence rate of $\mathcal{O}(\frac{1}{T})$ for strongly convex and smooth problems, where $T$ is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning.  Our results indicate that heterogeneity of data slows down the convergence, which matches empirical observations. Furthermore, we provide a necessary condition for \texttt{FedAvg} on non-iid data: the learning rate $\eta$ must decay, even if full-gradient is used; otherwise, the solution will be $\Omega (\eta)$ away from the optimal." />
  <meta name="citation_pdf_url" content="http://www.openreview.net/pdf?id=HJxNAnVtDS" />
  
  <meta name="citation_keywords" content="federated learning" />
  
  <meta name="citation_keywords" content="gradient descent" />
  
  <meta name="citation_keywords" content="learning rate" />
  
  <meta name="citation_keywords" content="optimization" />
  
  <body >
    <!-- NAV -->
    
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment.min.js"
  integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment-timezone/0.5.28/moment-timezone-with-data.min.js"
  integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
  crossorigin="anonymous"></script>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
    <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          
          <a class="nav-link" href="index.html">Home</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="calendar.html">Schedule</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="workshops.html">Workshops</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="papers.html">Papers</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="about.html">Help</a>
          
        </li>
        
      </ul>
    </div>
  </div>
</nav>
    <div class="container">
      <!-- Title -->
      <div class="pp-card m-3" style="">
        <div class="card-header">
          <h2 class="card-title main-title text-center" style="">
            On the Convergence of FedAvg on Non-IID Data
          </h2>
          <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Xiang Li" class="text-muted">Xiang Li</a>,
            
            <a href="papers.html?filter=authors&search=Kaixuan Huang" class="text-muted">Kaixuan Huang</a>,
            
            <a href="papers.html?filter=authors&search=Wenhao Yang" class="text-muted">Wenhao Yang</a>,
            
            <a href="papers.html?filter=authors&search=Shusen Wang" class="text-muted">Shusen Wang</a>,
            
            <a href="papers.html?filter=authors&search=Zhihua Zhang" class="text-muted">Zhihua Zhang</a>
            
          </h3>
          <p class="card-text text-center"><span class="">Keywords:</span>
            
            <a href="papers.html?filter=keywords&search=federated learning" class="text-secondary text-decoration-none">federated learning</a>,
            
            <a href="papers.html?filter=keywords&search=gradient descent" class="text-secondary text-decoration-none">gradient descent</a>,
            
            <a href="papers.html?filter=keywords&search=learning rate" class="text-secondary text-decoration-none">learning rate</a>,
            
            <a href="papers.html?filter=keywords&search=optimization" class="text-secondary text-decoration-none">optimization</a>
            
          </p>
          <div class="text-center p-3">
            <a class="card-link" data-toggle="collapse" role="button" href="#details">
            Abstract
            </a>
            <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf?id=HJxNAnVtDS">
            Paper
            </a>
            
            <a href="https://github.com/lx10077/fedavgpy" target="_blank"  class="card-link">
            Code
            </a>
            
            <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=HJxNAnVtDS">
            Reviews
            </a>
            <!--  -->
            <!-- <a href="38925562" target="_blank"  class="card-link"> -->
            <!--   Slides -->
            <!-- </a> -->
            <!--  -->
            <!-- </div> -->
            <!-- <div class="text-center "> -->
            <!-- <a href="chat.html?room=channel/poster_250" target="_blank"  class="card-link"> -->
            <!-- Chat -->
            <!-- </a> -->
          </div>
          <div class=" text-center text-muted text-monospace ">
            
            <div> Monday: Optimisation Theory 
            </div>
            
          </div>
        </div>
      </div>
      <div id="details" class="pp-card m-3 collapse">
        <div class="card-body">
          <p class="card-text">
          <div id="abstractExample">
            <span class="font-weight-bold">Abstract:</span>
            Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \texttt{FedAvg} on non-iid data and establish a convergence rate of $\mathcal{O}(\frac{1}{T})$ for strongly convex and smooth problems, where $T$ is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning.  Our results indicate that heterogeneity of data slows down the convergence, which matches empirical observations. Furthermore, we provide a necessary condition for \texttt{FedAvg} on non-iid data: the learning rate $\eta$ must decay, even if full-gradient is used; otherwise, the solution will be $\Omega (\eta)$ away from the optimal.
          </div>
          </p>
          <p></p>
        </div>
      </div>
    </div>
    <!-- SlidesLive -->
    <div class="container" style="background-color:white; padding: 0px;">
      <div class="row m-2">
        <div class="col-md-12 col-xs-12 my-auto p-2" >

          <div id="presentation-embed-38925562" class="slp my-auto"></div>
          <script src='https://slideslive.com/embed_presentation.js'></script>
          <script>
            embed = new SlidesLiveEmbed('presentation-embed-38925562', {
            presentationId: '38925562',
            autoPlay: false, // change to true to autoplay the embedded presentation
            verticalEnabled: true,
            allowHiddenControlsWhenPaused: true,
            hideTitle: true
            });
          </script>
        </div>
      </div>
    </div>

    <!-- Recs -->
    <p></p>
    <div  class="container" style="padding-bottom: 30px; padding-top:30px">
      <center>
        <h2> Similar Papers </h2>
      </center>
    </div>
    <p></p>
    <div  class="container" >
      <div class="row">
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_SJxIm0VtwH.html" class="text-muted">
                <h5 class="card-title" align="center">Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Mingrui Liu,
                
                Youssef Mroueh,
                
                Jerret Ross,
                
                Wei Zhang,
                
                Xiaodong Cui,
                
                Payel Das,
                
                Tianbao Yang,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJxIm0VtwH.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_BkglSTNFDB.html" class="text-muted">
                <h5 class="card-title" align="center">Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Yuanhao Wang,
                
                Kefan Dong,
                
                Xiaoyu Chen,
                
                Liwei Wang,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BkglSTNFDB.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_HJlxIJBFDr.html" class="text-muted">
                <h5 class="card-title" align="center">Sample Efficient Policy Gradient Methods with Recursive Variance Reduction</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Pan Xu,
                
                Felicia Gao,
                
                Quanquan Gu,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HJlxIJBFDr.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
      </div>
    </div>
    <script type="text/javascript">
  $(document).ready(function () {
  
  if (location.hash !== '') {
  $('a[href="' + location.hash + '"]').tab('show');
  }
  
  $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
  var hash = $(e.target).attr("href");
  if (hash.substr(0,1) == "#") {
  var position = $(window).scrollTop();
  location.replace("#" + hash.substr(1));
  $(window).scrollTop(position);
  }
  });
  
  });
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163955028-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  
  gtag('config', 'UA-163955028-1');
</script>
<footer class="footer bg-light p-4">
  <div class="container">
    <p class="float-right"><a href="#">Back to Top</a></p>
    <p class="text-center">Â© 2020 International Conference on Learning Representations</p>
  </div>
</footer>
  </body>
  <script src="static/js/time-extend.js"></script>
<script>
  $(document).ready(()=>{
    add_local_tz('.session_times');
  })
</script>
</html>