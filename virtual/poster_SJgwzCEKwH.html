<!doctype html>
<html lang="en">
  
  <head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="stylesheet" href="static/css/main.css">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <script src="static/js/typeahead.bundle.js"></script>
  <link rel="stylesheet" href="static/css/typeahead.css">
  <link rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
    crossorigin="anonymous">
  <link rel="stylesheet" href="static/css/lazy_load.css">
  <script src="static/js/lazy_load.js"></script>
  <title> ICLR: Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness </title>
</head>
  <meta name="citation_title" content="Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness" />
  
  <meta name="citation_author" content="Pu Zhao" />
  
  <meta name="citation_author" content="Pin-Yu Chen" />
  
  <meta name="citation_author" content="Payel Das" />
  
  <meta name="citation_author" content="Karthikeyan Natesan Ramamurthy" />
  
  <meta name="citation_author" content="Xue Lin" />
  
  <meta name="citation_publication_date" content="2020/04"/>
  <meta name="citation_conference_title" content="Eighth International Conference on Learning Representations" />
  <meta name="citation_abstract" content="Mode connectivity provides novel geometric insights on analyzing loss landscapes and enables building high-accuracy pathways between well-trained neural networks. In this work, we propose to employ mode connectivity in loss landscapes to study the adversarial robustness of deep neural networks, and provide novel methods for improving this robustness.  Our experiments cover various types of adversarial attacks applied to different network architectures and datasets. When network models are tampered with backdoor or error-injection attacks, our results demonstrate that the path connection learned using limited amount of bonafide data can effectively mitigate adversarial effects while maintaining the original accuracy on clean data. Therefore, mode connectivity provides users with the power to repair backdoored or error-injected models.  We also use mode connectivity to investigate the loss landscapes of regular and robust models against evasion attacks. Experiments show that there exists a barrier in adversarial robustness loss on the path connecting regular and adversarially-trained models.  A high correlation is observed between the adversarial robustness loss and the largest eigenvalue of the input Hessian matrix, for which theoretical justifications are provided.  Our results suggest that mode connectivity offers a holistic tool and practical means for evaluating and improving adversarial robustness." />
  <meta name="citation_pdf_url" content="http://www.openreview.net/pdf?id=SJgwzCEKwH" />
  
  <meta name="citation_keywords" content="adversarial" />
  
  <meta name="citation_keywords" content="adversarial attacks" />
  
  <meta name="citation_keywords" content="loss landscape" />
  
  <meta name="citation_keywords" content="robustness" />
  
  <body >
    <!-- NAV -->
    
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment.min.js"
  integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment-timezone/0.5.28/moment-timezone-with-data.min.js"
  integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
  crossorigin="anonymous"></script>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
    <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          
          <a class="nav-link" href="index.html">Home</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="calendar.html">Schedule</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="workshops.html">Workshops</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="papers.html">Papers</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="about.html">Help</a>
          
        </li>
        
      </ul>
    </div>
  </div>
</nav>
    <div class="container">
      <!-- Title -->
      <div class="pp-card m-3" style="">
        <div class="card-header">
          <h2 class="card-title main-title text-center" style="">
            Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness
          </h2>
          <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Pu Zhao" class="text-muted">Pu Zhao</a>,
            
            <a href="papers.html?filter=authors&search=Pin-Yu Chen" class="text-muted">Pin-Yu Chen</a>,
            
            <a href="papers.html?filter=authors&search=Payel Das" class="text-muted">Payel Das</a>,
            
            <a href="papers.html?filter=authors&search=Karthikeyan Natesan Ramamurthy" class="text-muted">Karthikeyan Natesan Ramamurthy</a>,
            
            <a href="papers.html?filter=authors&search=Xue Lin" class="text-muted">Xue Lin</a>
            
          </h3>
          <p class="card-text text-center"><span class="">Keywords:</span>
            
            <a href="papers.html?filter=keywords&search=adversarial" class="text-secondary text-decoration-none">adversarial</a>,
            
            <a href="papers.html?filter=keywords&search=adversarial attacks" class="text-secondary text-decoration-none">adversarial attacks</a>,
            
            <a href="papers.html?filter=keywords&search=loss landscape" class="text-secondary text-decoration-none">loss landscape</a>,
            
            <a href="papers.html?filter=keywords&search=robustness" class="text-secondary text-decoration-none">robustness</a>
            
          </p>
          <div class="text-center p-3">
            <a class="card-link" data-toggle="collapse" role="button" href="#details">
            Abstract
            </a>
            <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf?id=SJgwzCEKwH">
            Paper
            </a>
            
            <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=SJgwzCEKwH">
            Reviews
            </a>
            <!--  -->
            <!-- <a href="38925753" target="_blank"  class="card-link"> -->
            <!--   Slides -->
            <!-- </a> -->
            <!--  -->
            <!-- </div> -->
            <!-- <div class="text-center "> -->
            <!-- <a href="chat.html?room=channel/poster_405" target="_blank"  class="card-link"> -->
            <!-- Chat -->
            <!-- </a> -->
          </div>
          <div class=" text-center text-muted text-monospace ">
            
          </div>
        </div>
      </div>
      <div id="details" class="pp-card m-3 collapse">
        <div class="card-body">
          <p class="card-text">
          <div id="abstractExample">
            <span class="font-weight-bold">Abstract:</span>
            Mode connectivity provides novel geometric insights on analyzing loss landscapes and enables building high-accuracy pathways between well-trained neural networks. In this work, we propose to employ mode connectivity in loss landscapes to study the adversarial robustness of deep neural networks, and provide novel methods for improving this robustness.  Our experiments cover various types of adversarial attacks applied to different network architectures and datasets. When network models are tampered with backdoor or error-injection attacks, our results demonstrate that the path connection learned using limited amount of bonafide data can effectively mitigate adversarial effects while maintaining the original accuracy on clean data. Therefore, mode connectivity provides users with the power to repair backdoored or error-injected models.  We also use mode connectivity to investigate the loss landscapes of regular and robust models against evasion attacks. Experiments show that there exists a barrier in adversarial robustness loss on the path connecting regular and adversarially-trained models.  A high correlation is observed between the adversarial robustness loss and the largest eigenvalue of the input Hessian matrix, for which theoretical justifications are provided.  Our results suggest that mode connectivity offers a holistic tool and practical means for evaluating and improving adversarial robustness.
          </div>
          </p>
          <p></p>
        </div>
      </div>
    </div>
    <!-- SlidesLive -->
    <div class="container" style="background-color:white; padding: 0px;">
      <div class="row m-2">
        <div class="col-md-12 col-xs-12 my-auto p-2" >

          <div id="presentation-embed-38925753" class="slp my-auto"></div>
          <script src='https://slideslive.com/embed_presentation.js'></script>
          <script>
            embed = new SlidesLiveEmbed('presentation-embed-38925753', {
            presentationId: '38925753',
            autoPlay: false, // change to true to autoplay the embedded presentation
            verticalEnabled: true,
            allowHiddenControlsWhenPaused: true,
            hideTitle: true
            });
          </script>
        </div>
      </div>
    </div>

    <!-- Recs -->
    <p></p>
    <div  class="container" style="padding-bottom: 30px; padding-top:30px">
      <center>
        <h2> Similar Papers </h2>
      </center>
    </div>
    <p></p>
    <div  class="container" >
      <div class="row">
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_H1xscnEKDr.html" class="text-muted">
                <h5 class="card-title" align="center">Defending Against Physically Realizable Attacks on Image Classification</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Tong Wu,
                
                Liang Tong,
                
                Yevgeniy Vorobeychik,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/H1xscnEKDr.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_HyxJhCEFDS.html" class="text-muted">
                <h5 class="card-title" align="center">Intriguing Properties of Adversarial Training at Scale</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Cihang Xie,
                
                Alan Yuille,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HyxJhCEFDS.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_Hke0V1rKPS.html" class="text-muted">
                <h5 class="card-title" align="center">Jacobian Adversarially Regularized Networks for Robustness</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Alvin Chan,
                
                Yi Tay,
                
                Yew Soon Ong,
                
                Jie Fu,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/Hke0V1rKPS.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
      </div>
    </div>
    <script type="text/javascript">
  $(document).ready(function () {
  
  if (location.hash !== '') {
  $('a[href="' + location.hash + '"]').tab('show');
  }
  
  $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
  var hash = $(e.target).attr("href");
  if (hash.substr(0,1) == "#") {
  var position = $(window).scrollTop();
  location.replace("#" + hash.substr(1));
  $(window).scrollTop(position);
  }
  });
  
  });
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163955028-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  
  gtag('config', 'UA-163955028-1');
</script>
<footer class="footer bg-light p-4">
  <div class="container">
    <p class="float-right"><a href="#">Back to Top</a></p>
    <p class="text-center">© 2020 International Conference on Learning Representations</p>
  </div>
</footer>
  </body>
  <script src="static/js/time-extend.js"></script>
<script>
  $(document).ready(()=>{
    add_local_tz('.session_times');
  })
</script>
</html>